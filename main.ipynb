{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen IF4071 - Pembelajaran Mesin\n",
    "### 13514050 - Harry Octavianus Purba\n",
    "### 13514060 - Jeremia Kavin Raja P.\n",
    "### 13514082 - Rio Chandra Rajagukguk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis Data dan Penanganan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numbers\n",
    "\n",
    "def preProcessData(DATA, lenDATA, isSplitDataTarget):\n",
    "    dataTrain = {}\n",
    "    datasetColumn = lenDATA\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    dataTrainX = []\n",
    "\n",
    "    # Hardcode dataset target name\n",
    "    dataTrain['target_name'] = ['<=50K', '>50K']\n",
    "    \n",
    "    # Fit data TARGET & transform for labelling non-number\n",
    "    le.fit(DATA[datasetColumn - 1])\n",
    "    dataTrainY = le.transform(DATA[datasetColumn - 1])\n",
    "\n",
    "    # init target & length data target\n",
    "    dataTrain['target'] = []\n",
    "    lenDataTarget = len(dataTrainY)\n",
    "    \n",
    "    # FILL DATA TARGET\n",
    "    for i in range(lenDataTarget):\n",
    "        dataTrain['target'].append(dataTrainY[i])\n",
    "\n",
    "    # Fill temporary data feed\n",
    "    for i in range(datasetColumn - 1):\n",
    "        if(not(isinstance(DATA[i][0], numbers.Number))):\n",
    "            le.fit(DATA[i])\n",
    "            dataTrainX.append(le.transform(DATA[i]))\n",
    "        else:\n",
    "            dataTrainX.append(DATA[i])\n",
    "\n",
    "    # FILL DATA FEED\n",
    "    lenDataSet = len(dataTrainX[0])\n",
    "    lenAttr = len(dataTrainX)\n",
    "    dataTrain['data'] = []\n",
    "    for i in range(lenDataSet):\n",
    "        temp = []\n",
    "        for j in range(lenAttr):\n",
    "            temp.append(dataTrainX[j][i])\n",
    "        dataTrain['data'].append(temp)\n",
    "\n",
    "    # Checking\n",
    "    if isSplitDataTarget:\n",
    "        return dataTrain\n",
    "        \n",
    "    # FILL DATA for VISUALIZATION\n",
    "    dataForVisualization = []\n",
    "    lenDataTrain = len(dataTrain['data'])\n",
    "    for i in range(lenDataTrain):\n",
    "        temp = []\n",
    "        for j in range(lenAttr):\n",
    "            temp.append(dataTrain['data'][i][j])\n",
    "        temp.append(dataTrain['target'][i])\n",
    "\n",
    "        dataForVisualization.append(temp)\n",
    "\n",
    "    return dataForVisualization\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"DatasetEskperimen/CensusIncome/CencusIncome.data.txt\", header=None, \n",
    "            delimiter=\",\")\n",
    "datatest = pd.read_csv(\"DatasetEskperimen/CensusIncome/CencusIncome.test.txt\", header=None, \n",
    "            delimiter=\",\")\n",
    "\n",
    "dataTrain = preProcessData(dataset, 15, True)\n",
    "dataTest = preProcessData(datatest, 15, True)\n",
    "\n",
    "# dataTraining terdapat tiga key: data, target, target_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembelajaran ANN \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clfann = MLPClassifier(activation='logistic',solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15, 2), random_state=1)\n",
    "clfann.fit(dataTrain['data'], dataTrain['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembelajaran DTL dan ANN pada dataset dengan skema split train 90 % test 10 %\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "# census = \n",
    "\n",
    "class_names = dataTrain['target_name']\n",
    "\n",
    "# Membagi menjadi 90 % train dan 10 % test\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(dataTrain['data'], dataTrain['target'], test_size=0.1, random_state=1)\n",
    "\n",
    "# Pembelajaran DTL\n",
    "clfdtl2 = tree.DecisionTreeClassifier()\n",
    "clfdtl2 = clfdtl2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Pembelajaran ANN \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clfann2 = MLPClassifier(activation='logistic',solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15, 2), random_state=1)\n",
    "clfann2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Kinerja klasifikasi DTL : ', 0.8114829597789377)\n",
      "('Kinerja klasifikasi ANN : ', 0.80472827755603316)\n"
     ]
    }
   ],
   "source": [
    "# Kinerja klasifikasi DTL dengan skema split train 90 10\n",
    "print(\"Kinerja klasifikasi DTL : \",clfdtl2.score(X_valid,y_valid))\n",
    "\n",
    "# Kinerja klasifikasi ANN dengan skema split train 90 10\n",
    "print(\"Kinerja klasifikasi ANN : \",clfann2.score(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembelajaran DTL dan ANN pada dataset iris dengan skema 10-fold cross validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#iris = load_iris()\n",
    "#class_names = iris.target_names\n",
    "X = dataTrain['data']\n",
    "y = dataTrain['target']\n",
    "\n",
    "# Membagi dengan skema 10-fold cross validation\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "#Pembelajaran DTL\n",
    "clfdtl3 = tree.DecisionTreeClassifier()\n",
    "clfdtl3_cv_score = cross_val_score(clfdtl3, X, y, cv=kf, n_jobs=-1)\n",
    "\n",
    "#Pembelajaran ANN\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clfann3 = MLPClassifier(activation='logistic',solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15, 2), random_state=1)\n",
    "clfann3_cv_score = cross_val_score(clfann3, X, y, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Kinerja klasifikasi DTL\n",
    "print(\"Kinerja klasifikasi DTL (dengan data validasi) : \", clfdtl3_cv_score.mean())\n",
    "\n",
    "# Kinerja klasifikasi ANN\n",
    "print(\"Kinerja klasifikasi ANN (dengan data validasi) : \", clfann4_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi dengan data Test model tanpa split\n",
    "\n",
    "#DTL\n",
    "print(\"Kinerja klasifikasi DTL (dengan data validasi) : \",clfdtl.score(dataTest['data'],dataTest['target']))\n",
    "#ANN\n",
    "print(\"Kinerja klasifikasi DTL (dengan data validasi) : \",clfann.score(dataTest['data'],dataTest['target']))\n",
    "\n",
    "\n",
    "# Evaluasi dengan data Test dengan split train\n",
    "\n",
    "#DTL\n",
    "print(\"Kinerja klasifikasi DTL (dengan data validasi) : \",clfdtl2.score(dataTest['data'],dataTest['target']))\n",
    "#ANN\n",
    "print(\"Kinerja klasifikasi DTL (dengan data validasi) : \",clfann2.score(dataTest['data'],dataTest['target']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
